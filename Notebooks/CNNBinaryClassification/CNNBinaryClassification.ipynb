{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ca7d4e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# import torch.onnx\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "\n",
    "# import onnx\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "from numpy.fft import fft\n",
    "\n",
    "import math\n",
    "\n",
    "import audiomentations as AA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97440e25",
   "metadata": {},
   "source": [
    "# Préparation des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d6c242",
   "metadata": {},
   "source": [
    "###### Calculs de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "40aac7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcul des magnitudes d'un audio\n",
    "def magnitude(audio,window):\n",
    "    samples = len(audio)\n",
    "    power = 0\n",
    "\n",
    "    while(2**power <= samples):\n",
    "        power += 1\n",
    "\n",
    "    power -= 1\n",
    "    samples = 2**power\n",
    "\n",
    "    window = window/sum(window)\n",
    "    \n",
    "    weightedAudio = np.asarray(audio * window)\n",
    "    for i in range(weightedAudio.size):\n",
    "        weightedAudio[i] = weightedAudio[i]\n",
    "    hN = int((samples/2))                                            # size of positive spectrum, it includes sample 0\n",
    "    hM1 = int(math.floor((window.size+1)/2))                     # half analysis window size by rounding\n",
    "    hM2 = int(math.floor(window.size/2))                         # half analysis window size by floor\n",
    "    fftbuffer = np.zeros(samples)                                 # initialize buffer for FFT\n",
    "    fftbuffer[:hM1] = weightedAudio[hM2:]                              # zero-phase window in fftbuffer\n",
    "    fftbuffer[-hM2:] = weightedAudio[:hM2]\n",
    "\n",
    "    fftAudio = fft(fftbuffer)\n",
    "\n",
    "    absX = abs(fftAudio[:hN]) # compute ansolute value of positive side\n",
    "    absX[absX<np.finfo(float).eps] = np.finfo(float).eps    # if zeros add epsilon to handle log\n",
    "    mX = 20 * np.log10(absX)\n",
    "\n",
    "    return mX[:len(mX)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e36c9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcul des Mel-scale filter bank coefficients d'un audio\n",
    "def mel(magnitudes, nb_filters, window_size):\n",
    "    \n",
    "    pow_frames = ((1.0 / window_size) * ((np.asarray(magnitudes)) ** 2))  # Power Spectrum des magnitudes\n",
    "\n",
    "    #Calcul des bins\n",
    "    sampleRate = 8000\n",
    "    nqyst = int(sampleRate/2)\n",
    "    \n",
    "    high_freq_mel = (2595 * np.log10(1 + nqyst / 700))\n",
    "    mel_points = [] #taille nfilt+2\n",
    "    distance = high_freq_mel/(nb_filters+1)\n",
    "    for i in range(nb_filters+2):\n",
    "        mel_points.append(distance*i)\n",
    "    mel_points = np.asarray(mel_points)\n",
    "\n",
    "    #Calcul de l'échelle correspondante en hertz\n",
    "    hz_points = (700 * (10**(mel_points / 2595) - 1))\n",
    "    \n",
    "    #Création des bins\n",
    "    bins = np.floor((window_size + 1) * hz_points / sampleRate)\n",
    "    \n",
    "    fbank = np.zeros((nb_filters, int(np.floor(window_size / 2))))\n",
    "    \n",
    "    for m in range(1, nb_filters + 1):\n",
    "        f_m_minus = int(bins[m - 1])   # left\n",
    "        f_m = int(bins[m])             # center\n",
    "        f_m_plus = int(bins[m + 1])    # right\n",
    "\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bins[m - 1]) / (bins[m] - bins[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bins[m + 1] - k) / (bins[m + 1] - bins[m])\n",
    "    filter_banks = np.dot(pow_frames, fbank.T)\n",
    "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "    filter_banks = 20 * np.log10(filter_banks)  # dB\n",
    "    \n",
    "    return filter_banks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf77f8",
   "metadata": {},
   "source": [
    "###### Fonctions de récupération de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b97ea36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction de features Mel-scale filter bank coefficients sur des parties d'audios avec fenêtre glissante et en concatenant les Mel bands de l'audio obtenues\n",
    "def concatenation_mel_frames_extractor(audios, nb_filters, frame_length = 2048, window_size = 1024, hop_length = 256) :\n",
    "    sample_length = len(audios[0]) #longueur totale d'un audio\n",
    "    nb_concat = int(sample_length/frame_length) #nombe d'extraits audio indépendants à traiter (frame_length multiple de sample_length idéalement)\n",
    "    nb_frames = int((frame_length-window_size)/hop_length)+1 #nombre de frames de nb_filters par extrait audio\n",
    "    window = np.hamming(window_size)\n",
    "    coefs = []\n",
    "    for audio in audios :\n",
    "        coefs_local = []\n",
    "        for i in range(nb_concat):\n",
    "            ffts_local = []\n",
    "            signal = audio[i*frame_length:i*frame_length+(frame_length)]\n",
    "            for j in range (nb_frames):\n",
    "                signal_local = signal[j*hop_length:j*hop_length+window_size]\n",
    "                ffts_local.append(magnitude(signal_local, window))\n",
    "            coefs_mel = mel(ffts_local, nb_filters=nb_filters, window_size = window_size)\n",
    "            for coef in coefs_mel:\n",
    "                coefs_local.append(coef)\n",
    "        coefs.append(np.asarray(coefs_local))\n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0ac61",
   "metadata": {},
   "source": [
    "##### Ajout de bruits de fond avec audiomentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "982609b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_augmentation (audio, sr = 8000, proba = 0.5):\n",
    "    transform = AA.AddBackgroundNoise(\n",
    "        sounds_path=\"./datasetTrainTestToAugment/rp8kHz/backgroundNoise\",\n",
    "        min_snr_db=-44.7,\n",
    "        max_snr_db=-40.7,\n",
    "        p=proba\n",
    "        )\n",
    "\n",
    "    augmented_sound = transform(audio, sample_rate=sr)\n",
    "\n",
    "    return augmented_sound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1647f2",
   "metadata": {},
   "source": [
    "##### Découpage des audios dans une durée choisie, augmentation (optionnelle) avec bruits de fond et normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3383f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_raw_audio (audio, nbr_values, probability = 0):\n",
    "    audios = []\n",
    "    for n in range(int(len(audio)/nbr_values)-1):\n",
    "        sample = audio[int(n*nbr_values):int((n+1)*nbr_values)]\n",
    "        \n",
    "        #augmentation optionnelle de l'audio\n",
    "        if(probability != 0):\n",
    "            sample = audio_augmentation(np.asarray(sample).astype(np.int16), proba = probability)\n",
    "        \n",
    "        if(not np.isnan(sample[0])): #parfois addBackgroundNoise d'audiomentation renvoie des arrays de NaN (à régler car perte de sons)\n",
    "            #min-max normalization (x-xmin/xmax-xmin*(1--1)-1)\n",
    "            minimum = min(sample)\n",
    "            sample = ((np.asarray(sample)-minimum)/(max(sample)-minimum))*2-1        \n",
    "        \n",
    "            audios.append(sample.tolist())\n",
    "\n",
    "            #standardization\n",
    "            #mean = sum(sample)/len(sample)\n",
    "            #for i in range(len(sample)):\n",
    "            #    sample[i] = (sample[i]-mean)**2\n",
    "            #var = sum(sample)/len(sample)\n",
    "            #for i in range(len(sample)):\n",
    "            #    sample[i] = (sample[i]-mean)/var\n",
    "\n",
    "            #audios.append(sample)\n",
    "\n",
    "    return audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "332e561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal (path):\n",
    "    signal = []\n",
    "    if(\"wav\" in path):\n",
    "        fr, signal = wav.read(path)\n",
    "        signal = signal.tolist()\n",
    "    else :\n",
    "        f = open(path,\"r\")\n",
    "        lines = f.readlines()                               \n",
    "        for i in range (0,len(lines)) :\n",
    "            s = lines[i].replace(\"\\n\",\"\").replace(\"\\r\",\"\")\n",
    "            signal.append(int(s))\n",
    "    \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510392f",
   "metadata": {},
   "source": [
    "#### Récupération des features des audios des jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "ccf31cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8296\\3813085728.py:13: RuntimeWarning: overflow encountered in short_scalars\n",
      "  sample = ((np.asarray(sample)-minimum)/(max(sample)-minimum))*2-1\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\audiomentations\\core\\utils.py:81: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(np.mean(np.square(samples)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr d'extraits sirènes : 444; pourcentage : 0.5174825174825175%\n",
      "Nbr d'extraits autres :414; pourcentage : 0.4825174825174825%\n"
     ]
    }
   ],
   "source": [
    "siren_path = \"datasetTrainTestToAugment/rp8kHz/sirene_8kHz_Train.rw\"\n",
    "other_path = \"datasetTrainTestToAugment/rp8kHz/autre_8kHz_Train.rw\"\n",
    "\n",
    "extracted_features = []\n",
    "audio_normalized = []\n",
    "\n",
    "classSiren = \"siren\"\n",
    "classOther = \"other\"\n",
    "\n",
    "countSiren = 0\n",
    "countOther = 0\n",
    "\n",
    "# longueur des extraits audio\n",
    "nbr_values = 2048 #à 8 kHz = ~ 1/4s\n",
    "\n",
    "augmentation_proba = 0.5\n",
    "\n",
    "signalTEMP = get_signal(siren_path) # récupère les audios du jeu de données sirène\n",
    "audioTEMP = cut_raw_audio(signalTEMP, nbr_values, augmentation_proba) # coupe les audios dans la longueur nbr_values\n",
    "                                                                            # et les augmente de augmentation_proba %\n",
    "nbr_of_audios = len(audioTEMP)\n",
    "for i in range(nbr_of_audios):\n",
    "    extracted_features.append([0, classSiren, siren_path+\"_\"+str(i)+\"/\"+str(nbr_of_audios)]) #attribue un label à l'audio, lui associe un titre\n",
    "    audio_normalized.append(audioTEMP[i]) #stock avant le traitement de l'audio\n",
    "    countSiren +=1\n",
    "\n",
    "signalTEMP = get_signal(other_path)\n",
    "audioTEMP = cut_raw_audio(signalTEMP, nbr_values, augmentation_proba)\n",
    "nbr_of_audios = len(audioTEMP)\n",
    "for i in range(nbr_of_audios):\n",
    "    extracted_features.append([0, classOther, other_path+\"_\"+str(i)+\"/\"+str(nbr_of_audios)])\n",
    "    audio_normalized.append(audioTEMP[i])\n",
    "    countOther +=1\n",
    "    \n",
    "print(\"Nbr d'extraits sirènes : \"+str(countSiren) + \"; pourcentage : \"+str(countSiren/len(audio_normalized))+\"%\")\n",
    "print(\"Nbr d'extraits autres :\"+str(countOther) + \"; pourcentage : \"+str(countOther/len(audio_normalized))+\"%\")\n",
    "\n",
    "#calculs des features des extraits audio\n",
    "\n",
    "# features_audio_normalized = features_extractor_from_audios(audio_normalized)\n",
    "# features_audio_normalized = fft_extractor(audio_normalized)\n",
    "features_audio_normalized = concatenation_mel_frames_extractor(audio_normalized, frame_length = 2048, nb_filters = 32, window_size = 512, hop_length = 384)\n",
    "\n",
    "for i in range(len(features_audio_normalized)):\n",
    "    extracted_features[i][0] = features_audio_normalized[i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c749b3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_features[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db8cf75",
   "metadata": {},
   "source": [
    "##### Enregistrement des features du jeu de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "814d3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde des features sous format .pkl\n",
    "\n",
    "f = open('datasetFeatures/concat2048from2048_5frames_32coefs_Train_p05.pkl','wb') #jeu de train avec 50% d'augmentation\n",
    "\n",
    "pickle.dump(extracted_features, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9dc40a",
   "metadata": {},
   "source": [
    "#### Extraction des features du jeu de test fixe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "98db0f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr d'extraits sirènes : 50; pourcentage : 0.5319148936170213%\n",
      "Nbr d'extraits autres :44; pourcentage : 0.46808510638297873%\n"
     ]
    }
   ],
   "source": [
    "#extraction des features d'un jeu de test\n",
    "# jeux de test sans augmentation et avec augmentation à créer avec la partie :\n",
    "# \"Augmentation d'un jeu de test et enregistrement (pour avoir des augmentations non variables)\" à la fin du notebook\n",
    "\n",
    "siren_path_test = \"datasetTrainTestToAugment/rp8kHz/sirene_8kHz_Test.rw\"\n",
    "other_path_test = \"datasetTrainTestToAugment/rp8kHz/autre_8kHz_Test.rw\"\n",
    "\n",
    "# siren_path_test = \"datasetTrainTestToAugment/rp8kHz/sirene_8kHz_Test_Augmented_p1.wav\"\n",
    "# other_path_test = \"datasetTrainTestToAugment/rp8kHz/autre_8kHz_Test_Augmented_p1.wav\"\n",
    "\n",
    "# siren_path_test = \"datasetTrainTestToAugment/rp8kHz/sirene_8kHz_Test_Augmented_p05.wav\"\n",
    "# other_path_test = \"datasetTrainTestToAugment/rp8kHz/autre_8kHz_Test_Augmented_p05.wav\"\n",
    "\n",
    "classSiren = \"siren\"\n",
    "classOther = \"other\"\n",
    "\n",
    "countSiren = 0\n",
    "countOther = 0\n",
    "\n",
    "extracted_features_test = []\n",
    "audio_normalized_test = []\n",
    "\n",
    "signalTEMP = get_signal(siren_path_test)\n",
    "\n",
    "audioTEMP = cut_raw_audio(signalTEMP, nbr_values)\n",
    "nbr_of_audios = len(audioTEMP)\n",
    "for i in range(nbr_of_audios):\n",
    "    extracted_features_test.append([0, classSiren, siren_path_test+\"_\"+str(i)+\"/\"+str(nbr_of_audios)])\n",
    "    audio_normalized_test.append(audioTEMP[i])\n",
    "    countSiren +=1\n",
    "    \n",
    "signalTEMP = get_signal(other_path_test)\n",
    "\n",
    "audioTEMP = cut_raw_audio(signalTEMP, nbr_values)\n",
    "nbr_of_audios = len(audioTEMP)\n",
    "for i in range(nbr_of_audios):\n",
    "    extracted_features_test.append([0, classOther, other_path_test+\"_\"+str(i)+\"/\"+str(nbr_of_audios)])\n",
    "    audio_normalized_test.append(audioTEMP[i])\n",
    "    countOther +=1\n",
    "    \n",
    "print(\"Nbr d'extraits sirènes : \"+str(countSiren) + \"; pourcentage : \"+str(countSiren/len(audio_normalized_test))+\"%\")\n",
    "print(\"Nbr d'extraits autres :\"+str(countOther) + \"; pourcentage : \"+str(countOther/len(audio_normalized_test))+\"%\")\n",
    "    \n",
    "# features_audio_normalized_test = mel_frames_extractor(audio_normalized_test, nb_filters = 32, window_size = 2048, hop_length = 1024)\n",
    "features_audio_normalized_test = concatenation_mel_frames_extractor(audio_normalized_test, frame_length = 2048, nb_filters = 32, window_size = 512, hop_length = 384)\n",
    "\n",
    "\n",
    "for i in range(len(features_audio_normalized_test)):\n",
    "    extracted_features_test[i][0] = features_audio_normalized_test[i].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445bd07f",
   "metadata": {},
   "source": [
    "##### Enregistrement des features du jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "b763e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('datasetFeatures/concat2048from2048_5frames_32coefs_Test_p0','wb') #jeu de test sans augmentation\n",
    "# f = open('datasetFeatures/concat2048from2048_5frames_32coefs_Test_p05','wb') #jeu de test avec 50% d'augmentation\n",
    "# f = open('datasetFeatures/concat2048from2048_5frames_32coefs_Test_p1','wb') #jeu de test avec 100% d'augmentation\n",
    "\n",
    "pickle.dump(extracted_features_test, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac3fcf",
   "metadata": {},
   "source": [
    "# Apprentissage MLP et CNN Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745524b1",
   "metadata": {},
   "source": [
    "##### Séparation des données enregistrées en test/train  pour modèle Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "13d01662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3262, 3)\n"
     ]
    }
   ],
   "source": [
    "# Chargement du jeu de train\n",
    "\n",
    "f = open('datasetFeatures/concat2048from2048_5frames_32coefs_Train_p05.pkl','rb')\n",
    "\n",
    "Data = pickle.load(f)\n",
    "f.close()\n",
    "#transformation des données sous forme de DataFrame\n",
    "df = pd.DataFrame(Data,columns=['feature','class','file'])\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "4410f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(382, 3)\n"
     ]
    }
   ],
   "source": [
    "# Chargement du jeu de test\n",
    "\n",
    "f = open('datasetFeatures/concat2048from2048_5frames_32coefs_Test_p05.pkl','rb')\n",
    "\n",
    "Data_test = pickle.load(f)\n",
    "f.close()\n",
    "#transformation des données sous forme de DataFrame\n",
    "df_test = pd.DataFrame(Data_test,columns=['feature','class','file'])\n",
    "df_test.head()\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "30880c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mélange du dataframe suivant un int seed pour avoir toujours le même mélange\n",
    "df_sample = df.sample(frac=1, random_state=0)\n",
    "\n",
    "#création du dataset tensorflow avec les labels encodés\n",
    "labels = df_sample['class']\n",
    "labels = LabelEncoder().fit_transform(labels)\n",
    "numeric_features = df_sample['feature']\n",
    "for i in range(numeric_features.shape[0]):\n",
    "    numeric_features[i] = np.asarray(numeric_features[i]).astype('float32')\n",
    "    \n",
    "numeric_features = np.array([np.array(val) for val in numeric_features])\n",
    "\n",
    "numeric_dataset = tf.data.Dataset.from_tensor_slices((numeric_features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "a1cd9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_test.sample(frac=1, random_state=0)\n",
    "\n",
    "labels = df_sample['class']\n",
    "labels = LabelEncoder().fit_transform(labels)\n",
    "numeric_features = df_sample['feature']\n",
    "for i in range(numeric_features.shape[0]):\n",
    "    numeric_features[i] = np.asarray(numeric_features[i]).astype('float32')\n",
    "    \n",
    "numeric_features = np.array([np.array(val) for val in numeric_features])\n",
    "\n",
    "numeric_dataset_test = tf.data.Dataset.from_tensor_slices((numeric_features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "78184d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382\n"
     ]
    }
   ],
   "source": [
    "test_dataset = numeric_dataset_test#.skip(1)\n",
    "train_dataset = numeric_dataset\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "5ba5058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#création de batches sur les jeux de données\n",
    "batch_size = 15\n",
    "\n",
    "test_batches = test_dataset.batch(batch_size)\n",
    "train_batches = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "1ee6e749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(df['feature'][0]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bf3631",
   "metadata": {},
   "source": [
    "### CNN Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "2b5c0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    decay=0,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "normalizer = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "def get_cnn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=(5, 32, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "#         normalizer,\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0c81e",
   "metadata": {},
   "source": [
    "### MLP Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e027e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    decay=0.1,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "\n",
    "def get_mlp_model():\n",
    "    model = tf.keras.Sequential([\n",
    "#         normalizer,\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation ='sigmoid')\n",
    "      ])\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "b1ec1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "49527bed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.6623 - accuracy: 0.6070\n",
      "Epoch 2/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7364\n",
      "Epoch 3/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7906\n",
      "Epoch 4/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8326\n",
      "Epoch 5/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8495\n",
      "Epoch 6/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8642\n",
      "Epoch 7/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8811\n",
      "Epoch 8/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.8912\n",
      "Epoch 9/30\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.8994\n",
      "Epoch 10/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9059\n",
      "Epoch 11/30\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9139\n",
      "Epoch 12/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9185\n",
      "Epoch 13/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9218\n",
      "Epoch 14/30\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.9258\n",
      "Epoch 15/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9295\n",
      "Epoch 16/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9301\n",
      "Epoch 17/30\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9292\n",
      "Epoch 18/30\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9332\n",
      "Epoch 19/30\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.9347\n",
      "Epoch 20/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.9396\n",
      "Epoch 21/30\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.1667 - accuracy: 0.9399\n",
      "Epoch 22/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9402\n",
      "Epoch 23/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9323\n",
      "Epoch 24/30\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.9430\n",
      "Epoch 25/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9430\n",
      "Epoch 26/30\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9393\n",
      "Epoch 27/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9451\n",
      "Epoch 28/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9457\n",
      "Epoch 29/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9445\n",
      "Epoch 30/30\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23563af2460>"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entraînement du modèle sur le jeu de données train\n",
    "model.fit(train_batches, shuffle = 0, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "420c1b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9319371727748691 %\n"
     ]
    }
   ],
   "source": [
    "#évaluation de la précision sur le jeu de données test avec le score d'accuracy et une matrice de confusion\n",
    "y = model.predict(test_batches)\n",
    "\n",
    "y_pred = []\n",
    "for _ in y:\n",
    "    pred = 0\n",
    "    if(_[0]>=0.5):\n",
    "        pred = 1\n",
    "    y_pred.append(pred)\n",
    "\n",
    "y_true = []\n",
    "for inp, lab in test_dataset :\n",
    "    y_true.append(lab.numpy())\n",
    "    \n",
    "conf_mat = confusion_matrix(y_true,\n",
    "                            y_pred)\n",
    "\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "y = torch.tensor(labelencoder.fit_transform(['other','siren']))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=labelencoder.classes_, yticklabels=labelencoder.classes_, cbar=False)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "print(str((tp+tn)/len(test_dataset))+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "84f340cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_282 (Conv2D)         (None, 3, 30, 8)          80        \n",
      "                                                                 \n",
      " max_pooling2d_282 (MaxPooli  (None, 2, 15, 8)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_283 (Conv2D)         (None, 2, 15, 16)         1168      \n",
      "                                                                 \n",
      " max_pooling2d_283 (MaxPooli  (None, 1, 8, 16)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_141 (Flatten)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,549\n",
      "Trainable params: 2,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4ec16",
   "metadata": {},
   "source": [
    "###### Enregistrement du modèle entraîné en TensorflowLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "9220f372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmpql5vaaai\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmpql5vaaai\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is 28700 bytes\n"
     ]
    }
   ],
   "source": [
    "# conversion du modèle au format TensorFlowLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# sauvegarde du modèle\n",
    "open(\"finalcalculation_concat4096from8192_5frames32coefs_normalization_8kHz_augmented_p05_prct.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "basic_model_size = os.path.getsize(\"finalcalculation_concat4096from8192_5frames32coefs_normalization_8kHz_augmented_p05_prct.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pas utilisé car utilisation de EdgeImpulse avec le modèle créé ci-dessus pour importer le modèle sur Arduino\n",
    "## Header c++/Arduino à créer sur Colab via ce lien https://colab.research.google.com/drive/1HT0kYt1cFgC2lfZwO6sJVotYmjCrqhII#scrollTo=e6de24c5 en copie/collant le modèle TFLite dans Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b89312",
   "metadata": {},
   "source": [
    "##### Test du modèle tflite avec des coefs mel d'arduino (pour comparer les résultats des 2 calculs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1cfdd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.11 sur Arduino -> 0.113 sur python\n",
    "coefArduino1 = [[25.91,28.80,27.74,25.49,23.33,23.88,21.03,22.73,23.81,19.19,19.63,20.12,18.06,19.03,25.85,25.26,21.75,21.46,23.36,20.35,18.96,23.42,23.22,22.92,25.08,21.74,28.91,30.27,29.55,26.46,-300.00,-300.00],[18.89,19.61,15.95,14.22,13.21,15.88,14.59,17.08,17.05,14.99,13.24,12.60,14.43,16.40,23.55,18.43,14.97,20.63,20.54,17.87,15.57,18.65,18.82,19.98,24.45,21.07,27.76,24.87,27.46,25.39,-300.00,-300.00],[17.37,19.74,17.28,15.42,15.06,13.82,11.93,14.73,17.62,15.59,10.76,13.68,16.35,17.19,22.94,18.04,13.08,18.24,20.88,17.97,19.86,19.46,19.19,21.46,25.22,22.40,23.55,23.03,26.36,24.60,-300.00,-300.00],[19.25,20.65,17.75,16.70,17.38,10.49,11.64,15.60,17.77,12.27,11.85,13.34,13.84,16.16,20.15,19.08,15.92,17.87,17.11,15.75,16.54,19.84,14.63,21.07,24.07,21.38,27.30,25.38,27.10,25.69,-300.00,-300.00],[18.53,20.59,15.31,12.81,15.76,14.20,14.76,12.18,16.30,11.82,9.96,5.66,10.47,16.91,22.31,18.72,13.53,14.41,18.05,10.87,15.79,19.71,17.35,21.24,21.02,19.97,24.92,23.40,24.91,20.98,-300.00,-300.00],[16.14,18.59,17.00,16.00,17.45,12.17,11.10,12.48,16.56,13.02,11.93,14.14,10.73,17.95,23.01,17.54,15.86,15.41,18.63,18.37,17.48,19.77,17.91,22.29,23.60,22.61,27.43,24.06,25.42,26.08,-300.00,-300.00],[16.08,19.26,17.22,15.29,16.93,14.90,11.82,12.35,17.27,16.89,12.51,13.17,13.62,14.26,17.67,15.03,14.22,17.50,15.90,11.65,14.84,21.01,20.51,17.11,21.81,20.59,22.43,21.83,25.41,24.35,-300.00,-300.00],[16.32,20.14,15.88,15.65,15.97,14.20,14.60,12.76,15.83,11.56,9.43,8.56,12.10,15.49,22.26,16.69,15.04,17.46,18.88,13.94,17.27,21.78,19.54,16.94,23.42,18.37,23.39,22.91,24.90,22.98,-300.00,-300.00],[17.22,19.06,16.27,18.44,17.51,15.97,14.50,10.60,17.65,15.68,6.87,11.70,11.48,15.87,22.17,16.50,14.18,17.74,18.22,16.99,18.35,22.10,21.24,20.89,25.00,20.92,24.22,23.38,24.39,22.32,-300.00,-300.00],[18.48,20.07,16.87,17.74,15.29,13.20,13.97,10.79,14.64,16.26,11.51,11.62,10.68,12.42,18.61,15.35,10.10,12.78,15.30,14.17,16.60,21.67,23.56,20.11,21.08,19.70,24.60,23.43,24.11,23.07,-300.00,-300.00],[16.45,19.82,16.53,12.59,14.17,11.95,15.12,17.20,18.73,14.69,12.01,14.44,13.60,16.23,22.21,17.87,14.37,16.38,20.34,15.36,17.32,24.40,23.63,19.53,21.98,20.63,23.80,22.30,24.99,24.56,-300.00,-300.00],[17.19,19.42,16.12,14.45,12.75,11.26,11.61,13.26,15.88,16.15,14.42,12.78,7.59,14.30,22.26,16.82,14.03,13.78,18.14,15.04,15.81,22.22,20.98,19.01,21.25,17.92,22.85,20.21,22.17,22.55,-300.00,-300.00],[13.85,16.98,15.45,15.46,15.14,11.19,10.04,12.09,16.27,12.00,6.60,15.42,17.02,17.96,21.65,15.10,13.97,17.85,17.43,15.09,16.38,19.22,19.13,14.84,22.67,17.41,23.16,21.52,24.26,22.52,-300.00,-300.00],[14.47,17.97,10.95,12.69,14.78,15.04,15.56,14.60,16.54,13.24,11.24,15.56,14.51,15.23,21.91,17.79,13.97,15.97,21.76,15.84,15.55,23.54,21.87,15.60,24.77,21.02,25.28,24.76,25.16,24.42,-300.00,-300.00],[14.00,17.12,15.23,15.27,11.98,10.73,14.77,14.28,17.10,14.11,7.91,14.30,11.79,17.44,24.11,17.71,18.08,18.30,18.62,14.43,19.47,23.52,20.02,18.40,26.32,20.11,24.98,25.23,27.03,25.18,-300.00,-300.00],[15.51,18.14,11.07,11.92,11.37,13.14,11.50,16.50,17.40,7.77,7.67,15.18,16.23,18.15,20.59,16.22,11.83,18.84,22.02,17.52,21.24,24.76,22.64,22.34,24.48,22.71,27.03,25.36,27.16,25.50,-300.00,-300.00],[12.54,15.54,12.80,10.62,14.64,11.05,14.67,13.89,18.20,17.16,5.65,11.87,13.56,17.70,24.26,20.75,16.49,14.74,17.32,13.52,14.42,20.71,17.53,21.28,23.55,20.37,26.22,25.76,24.48,21.51,-300.00,-300.00],[12.34,16.51,10.69,13.54,11.69,8.44,11.28,14.07,15.11,12.18,11.72,9.20,13.01,17.33,24.73,22.70,18.42,19.76,22.68,21.68,20.02,19.61,22.33,23.05,27.66,25.99,28.70,30.56,25.51,22.08,-300.00,-300.00]]\n",
    "print(len(coefArduino1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "06a9bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1249]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"concat4096from8192_18frames32coefs_8kHz_normal.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "data = np.asarray(coefArduino1, dtype=np.float32).reshape(input_data.shape)\n",
    "interpreter.set_tensor(input_details[0]['index'], data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d86042",
   "metadata": {},
   "source": [
    "### Augmentation d'un jeu de test et enregistrement (pour avoir des augmentations non variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "157f10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_and_augment_test_audio (audio, probability):\n",
    "    audios = []\n",
    "    \n",
    "    for n in range(int(len(audio)/nbr_values)):\n",
    "        sample = audio[int(n*nbr_values):int((n)*nbr_values+nbr_values)]\n",
    "        sample = audio_augmentation(np.asarray(sample).astype(np.int16), proba = probability)\n",
    "        if(not np.isnan(sample[0])):\n",
    "            audios.append(sample)\n",
    "            \n",
    "    return np.asarray(audios).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eefa0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enregistrements de features de jeu de test avec plusieurs degrés d'augmentation (0%, 50% et 100%)\n",
    "#opération à ne faire qu'une fois par jeu de test\n",
    "\n",
    "siren_path_test = \"datasetTrainTestToAugment/rp8kHz/sirene_8kHz_Test.rw\"\n",
    "other_path_test = \"datasetTrainTestToAugment/rp8kHz/autre_8kHz_Test.rw\"\n",
    "\n",
    "signalTEMP = get_signal(siren_path_test)\n",
    "\n",
    "#cut_and_augment_test_audio : méthode à instancier plus bas\n",
    "\n",
    "#augmentations et sauvegarde du jeu de test augmenté\n",
    "wav.write(\"datasetTrainTestToAugment/rp8kHz/sirene_8kHz_Test_Augmented_p1.wav\", 8000, cut_and_augment_test_audio(signalTEMP,1).astype(np.int16))\n",
    "wav.write(\"datasetTrainTestToAugment/rp8kHz/sirene_8kHz_Test_Augmented_p05.wav\", 8000, cut_and_augment_test_audio(signalTEMP,0.5).astype(np.int16))\n",
    "\n",
    "signalTEMP = get_signal(other_path_test)\n",
    "\n",
    "#augmentations et sauvegarde du jeu de test augmenté\n",
    "wav.write(\"datasetTrainTestToAugment/rp8kHz/autre_8kHz_Test_Augmented_p1.wav\", 8000, cut_and_augment_test_audio(signalTEMP,1).astype(np.int16))\n",
    "wav.write(\"datasetTrainTestToAugment/rp8kHz/autre_8kHz_Test_Augmented_p05.wav\", 8000, cut_and_augment_test_audio(signalTEMP,0.5).astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc00a5",
   "metadata": {},
   "source": [
    "### Archives d'autres méthodes d'extraction de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "323fc3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcul le spectrogramme d'un audio (deprecated/not used)\n",
    "def spectrogram(samples, sample_rate, stride_ms = 10.0, \n",
    "                          window_ms = 20.0, max_freq = None, eps = 1e-14):\n",
    "    stride_size = 128\n",
    "    window_size = 256\n",
    "\n",
    "    truncate_size = (len(samples) - window_size) % stride_size\n",
    "    samples = samples[:len(samples) - truncate_size]\n",
    "    nshape = (window_size, 256)\n",
    "    nstrides = (samples.strides[0], samples.strides[0] * stride_size)\n",
    "    windows = np.lib.stride_tricks.as_strided(samples, \n",
    "                                          shape = nshape, strides = nstrides)\n",
    "    \n",
    "    weighting = np.hanning(window_size)[:, None]\n",
    "\n",
    "    fft = np.fft.rfft(windows * weighting, axis=0)\n",
    "    fft = np.absolute(fft)\n",
    "\n",
    "    scale = np.sum(weighting**2) * sample_rate\n",
    "    fft[1:-1, :] *= (2.0 / scale)\n",
    "    fft[(0, -1), :] /= scale\n",
    "    \n",
    "    freqs = float(sample_rate) / window_size * np.arange(fft.shape[0])\n",
    "    \n",
    "    ind = np.where(freqs <= max_freq)[0][-1] + 1\n",
    "    specgram = np.log(fft[:ind, :] + eps)\n",
    "    return specgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c0e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction de features MFCC des audios\n",
    "numberOfFeatures = 15\n",
    "\n",
    "def features_extractor_from_audios(audios):\n",
    "    mfcc = []\n",
    "    sample_rate = 8000\n",
    "    for audio in audios :\n",
    "        npaudio = np.asarray(audio).astype(float)\n",
    "        temp = librosa.feature.mfcc(y=npaudio, sr=sample_rate, n_mfcc=numberOfFeatures, hop_length = 128, n_fft = 256)\n",
    "        mfcc.append(np.mean(temp.T, axis=0))\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09c9b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction de feature MelSpectrogram des audios\n",
    "def librosa_mel_frames_extractor(audios, nb_filters, window_size = 256, hop_length = 128):\n",
    "    mels = []\n",
    "    for audio in audios :\n",
    "        S = librosa.feature.melspectrogram(y=np.asarray(audio).astype(float), sr=4100, n_mels = nb_filters, hop_length = hop_length, win_length = window_size)\n",
    "        mels.append(S)\n",
    "    return mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bdd808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction de features magnitudes des audios sans fenêtre glissante\n",
    "def fft_extractor(audios):\n",
    "    window = np.hamming(len(audios[0]))\n",
    "    ffts = []\n",
    "    for audio in audios :\n",
    "            \n",
    "        ffts.append(magnitude(audio, window))\n",
    "            \n",
    "    return ffts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a094229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction de feature spectrogramme des audios\n",
    "def spec_extractor (audios):\n",
    "    spectrograms = []\n",
    "    for audio in audios :\n",
    "        spectrograms.append(spectrogram(np.asarray(audio), 4100, max_freq=32000))\n",
    "    return spectrograms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
